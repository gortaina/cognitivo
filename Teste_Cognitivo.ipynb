{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisitos\n",
    "1. Conversão do formato dos arquivos: Converter o arquivo CSV presente no diretório data/input/users/load.csv, \n",
    "para um formato colunar de alta performance de leitura de sua escolha. Justificar brevemente a escolha do formato;\n",
    "\n",
    "2. Deduplicação dos dados convertidos: No conjunto de dados convertidos haverão múltiplas entradas para um mesmo registro, \n",
    "variando apenas os valores de alguns dos campos entre elas. Será necessário realizar um processo de deduplicação destes dados,\n",
    " a fim de apenas manter a última entrada de cada registro, usando como referência o id para identificação dos registros duplicados\n",
    " e a data de atualização (update_date) para definição do registro mais recente;\n",
    "\n",
    "3. Conversão do tipo dos dados deduplicados: No diretório config haverá um arquivo JSON de configuração (types_mapping.json),\n",
    " contendo os nomes dos campos e os respectivos tipos desejados de output. \n",
    " Utilizando esse arquivo como input, realizar um processo de conversão dos tipos dos campos descritos, no conjunto de dados deduplicados;\n",
    "\n",
    "# Notas gerais\n",
    "- Todas as operações devem ser realizadas utilizando Spark. \n",
    "O serviço de execução fica a seu critério, podendo utilizar tanto serviços locais como serviços em cloud. \n",
    "Justificar brevemente o serviço escolhido (EMR, Glue, Zeppelin, etc.).\n",
    "\n",
    "- Cada operação deve ser realizada no dataframe resultante do passo anterior, \n",
    "podendo ser persistido e carregado em diferentes conjuntos de arquivos após cada etapa ou executados em memória e apenas persistido após operação final.\n",
    "\n",
    "- Você tem liberdade p/ seguir a sequência de execução desejada;\n",
    "\n",
    "- Solicitamos a transformação de tipos de dados apenas de alguns campos. Os outros ficam a seu critério\n",
    "\n",
    "- O arquivo ou o conjunto de arquivos finais devem ser compactados e enviados por e-mail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solução:\n",
    "\n",
    "Foi feita em modo local utilizado o Spark 3.0.0 e o Jupyter Notebook, ambos do Miniconda que só tem os pacotes necessários.\n",
    "Há junto com esse notebook, o arquivo **teste_cognitivo.py** para ser submetido como job no Spark com o comando:\n",
    ">$SPARK_HOME/bin/spark-submit --master local[2] teste_cognitivo.py\n",
    "\n",
    "\n",
    "Como dito nas notas gerais sobre a execução desejada, sigo a sequência abaixo:\n",
    "    \n",
    "1. Deduplicação dos dados convertidos\n",
    "\n",
    "2. Conversão do tipo dos dados deduplicados\n",
    "\n",
    "3. Conversão do formato dos arquivos - escolhi o Parquet por sua eficiência de leitura e armazenamento. Seu formatos de arquivos consistem em grupos de linhas, cabeçalho e rodapé e, em cada grupo de linhas, os dados nas mesmas colunas são armazenados juntos, falando nisso o armazendamento de dados no HDFS tem uma replicação de no mínimo 3 copias fora os custos de processamento, I/O, rede, por ter uma boa taxa de compressão e I/O, ele reduz e muito os custos.\n",
    "\n",
    "4. Leitura do arquivo pós processado - incluí para efeitos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"Teste Cognitivo.ai\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"data/input/users/load.csv\", header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/types_mapping.json', 'r') as S:\n",
    "    new_types = json.load(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- create_date: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de registros\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "| id|                name|               email|          phone|             address|age|         create_date|         update_date|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9997|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-03-03 18:47:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9998|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-04-14 17:09:...|\n",
      "|  2|sherlock.holmes@c...|     Sherlock Holmes|(11) 94815-1623|221B Baker Street...| 34|2018-04-21 20:21:...|2018-04-21 20:21:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 91234-5678|124 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 04:07:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9999|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-05-23 10:13:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 98765-4321|122 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 05:08:...|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mostrando até 10º linha se houver\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Deduplicação dos dados convertidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(\"update_date\",ascending=False).dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "|id |name                              |email                |phone          |address                                       |age|create_date               |update_date               |\n",
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "|3  |spongebob.squarepants@cognitivo.ai|Spongebob Squarepants|(11) 98765-4321|122 Conch Street, Bikini Bottom, Pacific Ocean|13 |2018-05-19 04:07:06.854752|2018-05-19 05:08:07.964752|\n",
      "|1  |david.lynch@cognitivo.ai          |David Lynch          |(11) 99999-9999|Mulholland Drive, Los Angeles, CA, US         |72 |2018-03-03 18:47:01.954752|2018-05-23 10:13:59.594752|\n",
      "|2  |sherlock.holmes@cognitivo.ai      |Sherlock Holmes      |(11) 94815-1623|221B Baker Street, London, UK                 |34 |2018-04-21 20:21:24.364752|2018-04-21 20:21:24.364752|\n",
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mostrando até 10º linha se houver e sem truncar os dados\n",
    "df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversão do tipo dos dados deduplicados\n",
    "\n",
    " Substituindo o tipo de dado das colunas segundo arquivo types_mapping.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in new_types:\n",
    "    df = df.withColumn(key, F.col(key).cast(new_types[key]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversão do formato dos arquivos\n",
    "Escolhi o Parquet por sua eficiência de leitura e armazenamento. Seu formatos de arquivos consistem em grupos de linhas, cabeçalho e rodapé e, em cada grupo de linhas, os dados nas mesmas colunas são armazenados juntos, falando nisso o armazendamento de dados no HDFS tem uma replicação de no mínimo 3 copias fora os custos de processamento, I/O, rede, por ter uma boa taxa de compressão e I/O, ele reduz e muito os custos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"data/output/cognitivo/2020/06/25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Leitura do arquivo pós processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp=spark.read.parquet(\"data/output/cognitivo/2020/06/25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- create_date: timestamp (nullable = true)\n",
      " |-- update_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de registros\n",
    "dfp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "|id |name                              |email                |phone          |address                                       |age|create_date               |update_date               |\n",
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "|3  |spongebob.squarepants@cognitivo.ai|Spongebob Squarepants|(11) 98765-4321|122 Conch Street, Bikini Bottom, Pacific Ocean|13 |2018-05-19 04:07:06.854752|2018-05-19 05:08:07.964752|\n",
      "|2  |sherlock.holmes@cognitivo.ai      |Sherlock Holmes      |(11) 94815-1623|221B Baker Street, London, UK                 |34 |2018-04-21 20:21:24.364752|2018-04-21 20:21:24.364752|\n",
      "|1  |david.lynch@cognitivo.ai          |David Lynch          |(11) 99999-9999|Mulholland Drive, Los Angeles, CA, US         |72 |2018-03-03 18:47:01.954752|2018-05-23 10:13:59.594752|\n",
      "+---+----------------------------------+---------------------+---------------+----------------------------------------------+---+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfp.show(n=10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
